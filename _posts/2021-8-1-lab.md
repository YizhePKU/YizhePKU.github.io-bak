# 2021.8.5

发现之前跑的两个模型没保存输出（程序也没日记，日记全靠打印到标准输出）得重新跑。多亏了 git，我可以 checkout 一个能跑的历史版本。

简单有效的方法是把标准输出重定向到文件。有趣的是，如果有人问我怎么记日记，我大概会说用一个 logging 库之类的 -- 但是我想起来，12-factor app 推荐过把日记直接打印到标准输出，日记定向（routing）由其他进程管理。打印到标准输出的好处是，我无需修改代码就能控制日记的走向（类似环境变量的效果）。但是用 `print()` 当日记肯定是不行的，日记事件需要一定的结构，例如用 JSON，方便后续处理。

我担心的问题是，也许科研不需要这么严谨的日记；12-factor 主要是为长时间部署的应用考虑的，而科研代码一般就跑一两天就不管了。但另一方面，对于模型训练情况的监视（以及可视化）肯定很有帮助的，我只是不知道应该用多少东西合适。

我想要的主要是两个产品：一是 Python 里生成 JSON 日记的抽象层，二是网页查看日记和图表。ELK (Elasticsearch, Logstash, and Kibana) 三巨头太大了；Fluentd 似乎是很好的 router，但是没有可视化；winston 是 Javascript 热门的 JSON 日记库；GoAccess 似乎只分析网页服务器。试试 mongoDB 的 JSON 处理能力？



# 2021.8.5

开始处理 defect 任务。defect 任务用到的 codechef 数据集和 OJ104 形式一样，是一个四分类。我需要先把测试数据的格式转换为代码需要的形式，也就是带有`norm` 和 `label` 这两个 key 的 dict。之前提到，`norm` 虽然应该装已经 normalized 的数据，但代码实际上把数据重新 normalize 了一遍。

做 TBCNN 的时候遇到了数据预处理的问题；代码里很多参数是写死的，要改目录。



# 2021.8.4

Reverse-engineer the data pipeline... 用输入的程序分析出 `idx2txt` 和 `txt2idx` （`idx2txt[0]` 总是 `<unk>`，`txt2idx['<pad>']` 手动置为零）存下来。在测试的时候加载`idx2txt` 和 `txt2idx` （不加载 AST），词表大小需要约束到 `vocab_size`（`idx2txt`应该是按词频排序的，取前 `vocab_size` 个元素即可）。剩下的处理逻辑在 `Dataset` 类里实现：超出 `vocab_size` 的词用 `<unk>` 替换，句子长度小于`max_stmt_len` 的需要用 `<pad>` 补足，句子长度大于 `max_stmt_len` 的截断。最后喂给模型的输入是 `(stmts, stmt_len)` 二元组，其中`stmts.shape == (batch_size, max_stmt_cnt, max_stmt_len)`, `stmt_len.shape == (batch_size, max_stmt_cnt)`。

按照这个逻辑，我需要做的就是把输入按照空格切开，然后用 `txt2idx` 转换成 `id`（注意 `vocab_size` ），再切成 `stmt` （注意 `max_stmt_cnt` 和 `max_stmt_len` ），就可以喂给模型了。

实现很顺利，LSCNN 跑得很快，大概是因为模型规模比较小。



晚上看了看 TBCNN 的情况。TBCNN 是基于树的，所以要先把代码分析出 AST；这里用的是 `pycparser` 。AST 的结构定义在 `pycparser/_c_ast.cfg` 里；凡是没定义的节点都是字符串。AST 之后被展开为线性序列（`node`, `begin`, `end`）交给 `dgl.graph()` 处理；`node` 是把节点的字符串表示转换为 id 后的结果；`begin` 和 `end` 分别是每条边的起始节点和终止节点。`graph.ndata` 里保存了节点的特征信息。

和 LSCNN 的情况一样，我需要把数据处理的逻辑重新在 run 方法里实现一遍。模型输入就是 `DGLGraph` ，可以用 `dgl.batch` 把多个图合并为一个图处理。



# 2021.8.2

Attack 项目里的测试循环是一个 for 循环，似乎并没有 batch。我估计是代码复杂度的原因；要把现有的代码改成 batch 的太麻烦了。

有时我希望对比多个不同版本的运行结果：不同的模型/参数/输入数据等等。维护多套运行配置文件会很有利。

张煌昭告诉我 TBCNN 的数据预处理在 preprocess-tbcnn 目录里（独立运行的文件，没有能抽出来用的函数...）。我决定给 TBCNN 加一个 run 方法以匹配现有的接口；缺点是每次 run 都需要重新切词（TBCNN 需要重新构图），可能对速度有影响。

P.S. 张煌昭对于代码实现的态度是“无所谓，能跑出结果就行”。大概对于发 paper 这确实足够了...但不注意控制代码复杂度，到了一定程度是会拖慢开发效率的，我想科研代码也不会例外。



# 2021.8.1

本来打算先尝试 CodeBERT 跑 defect 任务，但是 defect 任务和 OJ104 用的不是同一个数据集，所以准备先做 LSCNN/TBCNN 跑 OJ104 的任务，先简后易嘛。

CARROT 用的数据集虽然也是 OJ104，但格式不一样，而且有自定义的数据加载代码 Dataset 类。我通过检查 CARROT 的数据集，能猜出 `data['raw_te']` 是输入代码，`data['y_te']` 是分类结果。这些数据可以对应到 Attack 项目期望的格式：`data['raw_te']` 对应到 `d['norm']`, `data['y_te']` 对应到 `d['label']`。

顺便说一句，Attack 里的数据 `d['norm']` 是已经 normalize 过的，代码里又重新 normalize 了一遍，是多余的。不过这里我正好利用现有代码把 CARROT 的数据做一下 normalize。

剩下的问题是，怎么把这些数据喂给 LSCNN/TBCNN？原有的 CodeBERT 模型是一个自定义的类，有个 run 方法负责 tokenize 和 batch。从 CARROT 那里复制来的 LSCNN/TBCNN 模型继承自 `nn.Module`，它们期望输入已经做好了 tokenize 和 batch。要么自己写一点代码，要么从 Dataset 类里面抄一点（代码挺难读懂的，没有注释）。

今天就到这里...

